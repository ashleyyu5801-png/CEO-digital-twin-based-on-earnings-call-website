{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process SeekingAlpha Test Data (2025)\n",
    "\n",
    "**Purpose:** Convert SeekingAlpha transcript txt files into structured Q&A pairs\n",
    "\n",
    "**Input:** `../Data/SeekingAlpha transcripts 2025/*.txt`\n",
    "\n",
    "**Output:** \n",
    "- `../Processed Data/speaker_turns.csv` - All speaker turns\n",
    "- `../Processed Data/test_qa_pairs.jsonl` - Jamie Dimon Q&A pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import shutil\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extract Speaker Turns from Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_speaker_turns(file_path):\n",
    "    \"\"\"\n",
    "    Extract all speaker turns from a transcript file.\n",
    "    \n",
    "    Speaker turn format:\n",
    "        [blank line]\n",
    "        Speaker Name\n",
    "        [optional title line]\n",
    "        [blank line]\n",
    "        Speaking content...\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries with: quarter, date, speaker, text, turn_number\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    # Remove line numbers (e.g., \"     1→\")\n",
    "    cleaned_lines = [re.sub(r'^\\s*\\d+→', '', line) for line in lines]\n",
    "    full_text = ''.join(cleaned_lines)\n",
    "    \n",
    "    # Extract quarter (e.g., \"Q1 2025\" -> \"2025Q1\")\n",
    "    quarter_match = re.search(r'Q(\\d+)\\s+(\\d{4})\\s+Earnings', full_text)\n",
    "    quarter = f\"{quarter_match.group(2)}Q{quarter_match.group(1)}\" if quarter_match else \"unknown\"\n",
    "    \n",
    "    # Extract conference call date\n",
    "    date_match = re.search(r'Earnings (?:Conference )?Call[^\\n]*\\n?([A-Z][a-z]+)\\s+(\\d{1,2}),\\s+(\\d{4})', full_text)\n",
    "    conference_date = f\"{date_match.group(1)} {date_match.group(2)} {date_match.group(3)}\" if date_match else \"unknown\"\n",
    "    \n",
    "    # Complete list of valid speakers (updated by user)\n",
    "    valid_speakers = [\n",
    "        'Operator',\n",
    "        'Jeremy Barnum',\n",
    "        'Ken Usdin',\n",
    "        'Jamie Dimon',\n",
    "        'James Dimon',\n",
    "        'Erika Najarian',\n",
    "        'John McDonald',\n",
    "        'Matt O\\'Connor',\n",
    "        'Steven Chubak',\n",
    "        'Gerard Cassidy',\n",
    "        'Ebrahim Poonawala',\n",
    "        'Jim Mitchell',\n",
    "        'Betsy Graseck',\n",
    "        'Mike Mayo',\n",
    "        'James Mitchell',\n",
    "        'Michael Mayo',\n",
    "        'Glenn Schorr',\n",
    "        'Saul Martinez',\n",
    "        'Betsy Lynn Graseck',\n",
    "        'Christoph M. Kotowski',\n",
    "        'Christopher Edward McGratty',\n",
    "        'Ebrahim Huseini Poonawala',\n",
    "        'Gerard Sean Cassidy',\n",
    "        'Glenn Paul Schorr',\n",
    "        'James Francis Mitchell',\n",
    "        'John Eamon McDonald',\n",
    "        'Kenneth Michael Usdin',\n",
    "        'Matthew Derek O\\'Connor',\n",
    "        'Michael Lawrence Mayo',\n",
    "        'Steven A. Alexopoulos',\n",
    "        'L. Erika Penala',\n",
    "        'Kenneth Usdin',\n",
    "        'Christopher McGratty'\n",
    "    ]\n",
    "    \n",
    "    # Find Q&A section\n",
    "    qa_start = full_text.find(\"Question-and-Answer Session\")\n",
    "    if qa_start == -1:\n",
    "        print(f\"Warning: No Q&A section found in {file_path.name}\")\n",
    "        return []\n",
    "    \n",
    "    qa_text = full_text[qa_start:]\n",
    "    \n",
    "    # Build regex pattern - escape special characters and sort by length (longest first)\n",
    "    escaped_names = [re.escape(name) for name in valid_speakers]\n",
    "    escaped_names.sort(key=len, reverse=True)\n",
    "    names_pattern = '|'.join(escaped_names)\n",
    "    \n",
    "    # Pattern: blank line + speaker name + newline\n",
    "    pattern = rf'\\n\\n({names_pattern})\\n'\n",
    "    \n",
    "    # Find all speaker positions\n",
    "    speaker_matches = list(re.finditer(pattern, qa_text))\n",
    "    \n",
    "    if not speaker_matches:\n",
    "        print(f\"Warning: No speaker turns found in {file_path.name}\")\n",
    "        return []\n",
    "    \n",
    "    # Title patterns to strip from content\n",
    "    # These patterns match title/company lines that appear immediately after speaker name\n",
    "    title_patterns = [\n",
    "        # Job titles\n",
    "        r'^(Executive VP & CFO|Chairman & CEO|Chief Financial Officer|Chairman & Chief Executive Officer)\\s*\\n+',\n",
    "        # Company names with \"Research Division\"\n",
    "        r'^.+,\\s*Research Division\\s*\\n+',\n",
    "        # Investment banks and securities firms (without Research Division)\n",
    "        r'^(?:[A-Z][a-zA-Z\\s&,\\.]+)?(?:Securities|Capital Markets|Investment Bank)(?:\\s*,\\s*Inc\\.)?(?:\\s*,\\s*Research Division)?\\s*\\n+',\n",
    "        # Specific patterns for Q3 format\n",
    "        r'^[A-Z][a-zA-Z\\s&,\\.]+(?:LLC|LLP|Inc\\.|L\\.P\\.)\\s*,\\s*Research Division\\s*\\n+',\n",
    "        # Standalone company names like \"Bernstein Autonomous LLP\"\n",
    "        r'^[A-Z][a-zA-Z\\s&,\\.]+(?:LLC|LLP|Inc\\.|L\\.P\\.|LP)\\s*\\n+',\n",
    "        # Other institutional names like \"Seaport Research Partners\"\n",
    "        r'^[A-Z][a-z]+\\s+(?:Research\\s+)?(?:Autonomous|Partners|Group|Advisors|Associates)(?:\\s+(?:LLC|LLP|Inc\\.|L\\.P\\.))?\\s*\\n+',\n",
    "    ]\n",
    "    \n",
    "    def strip_title_prefix(text):\n",
    "        \"\"\"Remove title/company prefix from text\"\"\"\n",
    "        for pattern in title_patterns:\n",
    "            text = re.sub(pattern, '', text, flags=re.MULTILINE)\n",
    "        return text.strip()\n",
    "    \n",
    "    # Extract speaker turns\n",
    "    speaker_turns = []\n",
    "    \n",
    "    for i, match in enumerate(speaker_matches):\n",
    "        speaker = match.group(1).strip()\n",
    "        \n",
    "        # Get text from end of this match to start of next match (or end of qa_text)\n",
    "        text_start = match.end()\n",
    "        \n",
    "        if i + 1 < len(speaker_matches):\n",
    "            text_end = speaker_matches[i + 1].start()\n",
    "        else:\n",
    "            text_end = len(qa_text)\n",
    "        \n",
    "        text = qa_text[text_start:text_end].strip()\n",
    "        \n",
    "        # Strip title prefix (in case title line was included in text)\n",
    "        text = strip_title_prefix(text)\n",
    "        \n",
    "        # Skip empty text\n",
    "        if not text:\n",
    "            continue\n",
    "        \n",
    "        speaker_turns.append({\n",
    "            'quarter': quarter,\n",
    "            'date': conference_date,\n",
    "            'turn_number': len(speaker_turns) + 1,\n",
    "            'speaker': speaker,\n",
    "            'text': text,\n",
    "            'word_count': len(text.split())\n",
    "        })\n",
    "    \n",
    "    return speaker_turns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting speaker turns...\n",
      "\n",
      "jpmorgan_chase_2025q1.txt:\n",
      "  Total turns: 108\n",
      "  Jamie/James: 23 | Jeremy: 32 | Analysts: 39\n",
      "jpmorgan_chase_2025q2.txt:\n",
      "  Total turns: 128\n",
      "  Jamie/James: 34 | Jeremy: 39 | Analysts: 39\n",
      "jpmorgan_chase_2025q3.txt:\n",
      "  Total turns: 60\n",
      "  Jamie/James: 11 | Jeremy: 20 | Analysts: 18\n",
      "\n",
      "Total speaker turns extracted: 296\n"
     ]
    }
   ],
   "source": [
    "# Process all transcript files\n",
    "input_dir = Path(\"../Data/SeekingAlpha transcripts 2025\")\n",
    "txt_files = sorted(input_dir.glob(\"jpmorgan_chase_2025q*.txt\"))\n",
    "\n",
    "all_speaker_turns = []\n",
    "print(\"Extracting speaker turns...\\n\")\n",
    "\n",
    "for txt_file in txt_files:\n",
    "    turns = extract_speaker_turns(txt_file)\n",
    "    all_speaker_turns.extend(turns)\n",
    "    \n",
    "    # Count by speaker type\n",
    "    jamie_count = sum(1 for t in turns if t['speaker'] in ['Jamie Dimon', 'James Dimon'])\n",
    "    jeremy_count = sum(1 for t in turns if t['speaker'] == 'Jeremy Barnum')\n",
    "    analyst_count = sum(1 for t in turns if t['speaker'] not in ['Jamie Dimon', 'James Dimon', 'Jeremy Barnum', 'Operator'])\n",
    "    \n",
    "    print(f\"{txt_file.name}:\")\n",
    "    print(f\"  Total turns: {len(turns)}\")\n",
    "    print(f\"  Jamie/James: {jamie_count} | Jeremy: {jeremy_count} | Analysts: {analyst_count}\")\n",
    "\n",
    "print(f\"\\nTotal speaker turns extracted: {len(all_speaker_turns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Save Speaker Turns to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAVED: ../Processed Data/speaker_turns.csv\n",
      "================================================================================\n",
      "Total turns: 296\n",
      "\n",
      "Breakdown by speaker type:\n",
      "speaker_type\n",
      "Analyst     96\n",
      "CFO         91\n",
      "CEO         68\n",
      "Operator    41\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Breakdown by quarter:\n",
      "speaker_type  Analyst  CEO  CFO  Operator\n",
      "quarter                                  \n",
      "2025Q1             39   23   32        14\n",
      "2025Q2             39   34   39        16\n",
      "2025Q3             18   11   20        11\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame and save\n",
    "df_turns = pd.DataFrame(all_speaker_turns)\n",
    "\n",
    "# Normalize speaker names to handle variations\n",
    "def normalize_name(speaker):\n",
    "    \"\"\"Normalize speaker names to canonical form\"\"\"\n",
    "    if 'Dimon' in speaker:\n",
    "        return 'Jamie Dimon'\n",
    "    elif 'Barnum' in speaker:\n",
    "        return 'Jeremy Barnum'\n",
    "    return speaker\n",
    "\n",
    "df_turns['speaker'] = df_turns['speaker'].apply(normalize_name)\n",
    "\n",
    "# Add speaker type column for easier filtering\n",
    "def classify_speaker(speaker):\n",
    "    if speaker == 'Jamie Dimon':\n",
    "        return 'CEO'\n",
    "    elif speaker == 'Jeremy Barnum':\n",
    "        return 'CFO'\n",
    "    elif speaker == 'Operator':\n",
    "        return 'Operator'\n",
    "    else:\n",
    "        return 'Analyst'\n",
    "\n",
    "df_turns['speaker_type'] = df_turns['speaker'].apply(classify_speaker)\n",
    "\n",
    "# Save to CSV\n",
    "output_csv = Path(\"../Processed Data/speaker_turns.csv\")\n",
    "output_csv.parent.mkdir(exist_ok=True)\n",
    "df_turns.to_csv(output_csv, index=False)\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"SAVED: {output_csv}\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total turns: {len(df_turns)}\")\n",
    "print(f\"\\nBreakdown by speaker type:\")\n",
    "print(df_turns['speaker_type'].value_counts())\n",
    "print(f\"\\nBreakdown by quarter:\")\n",
    "print(df_turns.groupby(['quarter', 'speaker_type']).size().unstack(fill_value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extract Jamie Dimon Q&A Pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_qa_pairs(df_turns, min_words=20):\n",
    "    \"\"\"\n",
    "    Extract Q&A pairs from speaker turns.\n",
    "    \n",
    "    Logic:\n",
    "    - For each analyst turn, collect all Jamie responses until next analyst\n",
    "    - Only include if Jamie's combined response > min_words\n",
    "    \"\"\"\n",
    "    qa_pairs = []\n",
    "    \n",
    "    # Group by quarter and process each separately\n",
    "    for quarter in df_turns['quarter'].unique():\n",
    "        quarter_turns = df_turns[df_turns['quarter'] == quarter].reset_index(drop=True)\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(quarter_turns):\n",
    "            turn = quarter_turns.iloc[i]\n",
    "            \n",
    "            # Skip if not an analyst\n",
    "            if turn['speaker_type'] != 'Analyst':\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            # This is an analyst question\n",
    "            analyst_name = turn['speaker']\n",
    "            analyst_question = turn['text']\n",
    "            date = turn['date']\n",
    "            \n",
    "            # Collect Jamie's responses until next analyst\n",
    "            jamie_responses = []\n",
    "            j = i + 1\n",
    "            \n",
    "            while j < len(quarter_turns):\n",
    "                next_turn = quarter_turns.iloc[j]\n",
    "                \n",
    "                # Stop if we hit another analyst\n",
    "                if next_turn['speaker_type'] == 'Analyst':\n",
    "                    break\n",
    "                \n",
    "                # Collect Jamie/James responses\n",
    "                if next_turn['speaker_type'] == 'CEO':\n",
    "                    jamie_responses.append(next_turn['text'])\n",
    "                \n",
    "                j += 1\n",
    "            \n",
    "            # Check if Jamie responded substantially\n",
    "            if jamie_responses:\n",
    "                combined_answer = '\\n\\n'.join(jamie_responses)\n",
    "                word_count = len(combined_answer.split())\n",
    "                \n",
    "                if word_count > min_words:\n",
    "                    qa_pairs.append({\n",
    "                        'quarter': quarter,\n",
    "                        'date': date,\n",
    "                        'analyst': analyst_name,\n",
    "                        'question': analyst_question,\n",
    "                        'answer': combined_answer\n",
    "                    })\n",
    "            \n",
    "            i += 1\n",
    "    \n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Jamie Dimon Q&A pairs (>20 words)...\n",
      "\n",
      "Total Q&A pairs extracted: 43\n",
      "\n",
      "Breakdown by quarter:\n",
      "  2025Q1: 16 Q&A pairs\n",
      "  2025Q2: 19 Q&A pairs\n",
      "  2025Q3: 8 Q&A pairs\n"
     ]
    }
   ],
   "source": [
    "# Extract Q&A pairs\n",
    "print(\"Extracting Jamie Dimon Q&A pairs (>20 words)...\\n\")\n",
    "\n",
    "qa_pairs = extract_qa_pairs(df_turns, min_words=20)\n",
    "\n",
    "print(f\"Total Q&A pairs extracted: {len(qa_pairs)}\")\n",
    "print(f\"\\nBreakdown by quarter:\")\n",
    "quarter_counts = Counter([pair['quarter'] for pair in qa_pairs])\n",
    "for quarter in sorted(quarter_counts.keys()):\n",
    "    print(f\"  {quarter}: {quarter_counts[quarter]} Q&A pairs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save Q&A Pairs to JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAVED: ../Processed Data/test_qa_pairs.jsonl\n",
      "================================================================================\n",
      "Total Q&A pairs: 43\n"
     ]
    }
   ],
   "source": [
    "# Save to JSONL\n",
    "output_file = Path(\"../Processed Data/test_qa_pairs.jsonl\")\n",
    "output_file.parent.mkdir(exist_ok=True)\n",
    "\n",
    "# Create backup if file exists\n",
    "if output_file.exists():\n",
    "    backup_file = output_file.parent / f\"test_qa_pairs_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.jsonl\"\n",
    "    shutil.copy(output_file, backup_file)\n",
    "    print(f\"Backup created: {backup_file.name}\\n\")\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    for pair in qa_pairs:\n",
    "        json.dump(pair, f, ensure_ascii=False)\n",
    "        f.write('\\n')\n",
    "\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"SAVED: {output_file}\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total Q&A pairs: {len(qa_pairs)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
